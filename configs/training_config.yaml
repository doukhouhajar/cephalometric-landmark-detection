training:
  device: auto        
  epochs: 80
  batch_size: 4
  learning_rate: 0.001  # Increased for faster initial learning
  weight_decay: 0.0001

  loss:
    type: awing  # Options: awing, weighted_mse, focal_mse, mse
    coord_weight: 0.0
    use_deep_supervision: true
    deep_supervision_weights: [1.0, 0.4, 0.2, 0.1]

  optimizer:
    name: adamw

  scheduler:
    use: true
    type: cosine  # CosineAnnealingLR
    warmup_epochs: 5
    min_lr: 0.00001

data:
  img_size: 224
  heatmap_sigma: 10  # Large sigma to combat class imbalance

  train_csv: datasets/raw/train_senior.csv
  val_csv: datasets/raw/test1_senior.csv
  img_root: datasets/raw/cepha400/cepha400

outputs:
  checkpoint_path: outputs/checkpoints/la_unet_swin_cbam.pth
